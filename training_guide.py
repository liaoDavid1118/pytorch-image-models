#!/usr/bin/env python3
"""
PyTorch Image Models (timm) è®­ç»ƒæŒ‡å—
"""

# 1. åŸºç¡€è®­ç»ƒå‘½ä»¤ç¤ºä¾‹
def basic_training_commands():
    """åŸºç¡€è®­ç»ƒå‘½ä»¤"""
    print("=== åŸºç¡€è®­ç»ƒå‘½ä»¤ ===")
    
    commands = [
        # åŸºç¡€ImageNetè®­ç»ƒ
        "python train.py /path/to/imagenet --model resnet50 --batch-size 256 --lr 0.1",
        
        # ä½¿ç”¨é¢„è®­ç»ƒæƒé‡è¿›è¡Œå¾®è°ƒ
        "python train.py /path/to/dataset --model resnet50 --pretrained --num-classes 10 --batch-size 128 --lr 0.01",
        
        # EfficientNetè®­ç»ƒ
        "python train.py /path/to/dataset --model efficientnet_b0 --batch-size 128 --lr 0.1 --epochs 300",
        
        # Vision Transformerè®­ç»ƒ
        "python train.py /path/to/dataset --model vit_base_patch16_224 --batch-size 64 --lr 0.001 --opt adamw",
        
        # åˆ†å¸ƒå¼è®­ç»ƒ
        "python -m torch.distributed.launch --nproc_per_node=4 train.py /path/to/dataset --model resnet50",
    ]
    
    for i, cmd in enumerate(commands, 1):
        print(f"{i}. {cmd}")

# 2. è®­ç»ƒå‚æ•°é…ç½®
def training_parameters():
    """è®­ç»ƒå‚æ•°è¯¦è§£"""
    print("\n=== è®­ç»ƒå‚æ•°é…ç½® ===")
    
    params = {
        "æ•°æ®é›†å‚æ•°": {
            "--data-dir": "æ•°æ®é›†æ ¹ç›®å½•",
            "--dataset": "æ•°æ®é›†ç±»å‹ (å¦‚ torch/cifar10, hfds/imagenet-1k)",
            "--train-split": "è®­ç»ƒé›†åˆ†å‰²åç§° (é»˜è®¤: train)",
            "--val-split": "éªŒè¯é›†åˆ†å‰²åç§° (é»˜è®¤: validation)",
            "--num-classes": "åˆ†ç±»æ•°é‡",
            "--input-size": "è¾“å…¥å›¾åƒå°ºå¯¸ (å¦‚ 3 224 224)",
        },
        
        "æ¨¡å‹å‚æ•°": {
            "--model": "æ¨¡å‹æ¶æ„åç§°",
            "--pretrained": "ä½¿ç”¨é¢„è®­ç»ƒæƒé‡",
            "--resume": "ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ",
            "--initial-checkpoint": "åŠ è½½åˆå§‹æ£€æŸ¥ç‚¹",
        },
        
        "è®­ç»ƒå‚æ•°": {
            "--epochs": "è®­ç»ƒè½®æ•°",
            "--batch-size": "æ‰¹æ¬¡å¤§å°",
            "--lr": "å­¦ä¹ ç‡",
            "--opt": "ä¼˜åŒ–å™¨ (sgd, adam, adamw, rmspropç­‰)",
            "--momentum": "åŠ¨é‡ (SGD)",
            "--weight-decay": "æƒé‡è¡°å‡",
        },
        
        "æ•°æ®å¢å¼º": {
            "--aa": "AutoAugmentç­–ç•¥",
            "--mixup": "Mixup alphaå€¼",
            "--cutmix": "CutMix alphaå€¼",
            "--drop-path": "DropPathæ¯”ç‡",
            "--reprob": "Random Erasingæ¦‚ç‡",
        }
    }
    
    for category, param_dict in params.items():
        print(f"\n{category}:")
        for param, desc in param_dict.items():
            print(f"  {param:<20}: {desc}")

# 3. ä¸åŒåœºæ™¯çš„è®­ç»ƒé…ç½®
def training_scenarios():
    """ä¸åŒè®­ç»ƒåœºæ™¯çš„é…ç½®"""
    print("\n=== ä¸åŒè®­ç»ƒåœºæ™¯ ===")
    
    scenarios = {
        "ä»å¤´è®­ç»ƒImageNet": [
            "python train.py /imagenet",
            "--model resnet50",
            "--batch-size 256",
            "--lr 0.1",
            "--epochs 90",
            "--opt sgd",
            "--momentum 0.9",
            "--weight-decay 1e-4",
            "--sched cosine",
            "--aa rand-m9-mstd0.5-inc1",
            "--mixup 0.2",
            "--cutmix 1.0",
            "--drop-path 0.1"
        ],
        
        "å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹": [
            "python train.py /custom_dataset",
            "--model resnet50",
            "--pretrained",
            "--num-classes 10",
            "--batch-size 128",
            "--lr 0.01",
            "--epochs 50",
            "--opt sgd",
            "--weight-decay 1e-4",
            "--sched step",
            "--decay-epochs 20"
        ],
        
        "Vision Transformerè®­ç»ƒ": [
            "python train.py /imagenet",
            "--model vit_base_patch16_224",
            "--batch-size 64",
            "--lr 0.001",
            "--epochs 300",
            "--opt adamw",
            "--weight-decay 0.05",
            "--sched cosine",
            "--warmup-epochs 10",
            "--mixup 0.8",
            "--cutmix 1.0",
            "--drop-path 0.1"
        ],
        
        "è½»é‡çº§æ¨¡å‹è®­ç»ƒ": [
            "python train.py /dataset",
            "--model mobilenetv3_large_100",
            "--batch-size 256",
            "--lr 0.1",
            "--epochs 200",
            "--opt rmsprop",
            "--decay-rate 0.9",
            "--weight-decay 1e-5",
            "--aa rand-m7-mstd0.5"
        ]
    }
    
    for scenario, commands in scenarios.items():
        print(f"\n{scenario}:")
        command = " \\\n    ".join(commands)
        print(f"  {command}")

# 4. é«˜çº§è®­ç»ƒé€‰é¡¹
def advanced_training_options():
    """é«˜çº§è®­ç»ƒé€‰é¡¹"""
    print("\n=== é«˜çº§è®­ç»ƒé€‰é¡¹ ===")
    
    options = {
        "æ··åˆç²¾åº¦è®­ç»ƒ": "--amp",
        "æ¢¯åº¦ç´¯ç§¯": "--grad-accum-steps 4",
        "æ¢¯åº¦æ£€æŸ¥ç‚¹": "--grad-checkpointing",
        "åˆ†å¸ƒå¼è®­ç»ƒ": "python -m torch.distributed.launch --nproc_per_node=4",
        "æ¨¡å‹EMA": "--model-ema --model-ema-decay 0.9999",
        "æ ‡ç­¾å¹³æ»‘": "--smoothing 0.1",
        "éšæœºæ·±åº¦": "--drop-path 0.1",
        "é€šé“æœ€åå†…å­˜å¸ƒå±€": "--channels-last",
        "ç¼–è¯‘ä¼˜åŒ–": "--torchcompile",
    }
    
    for option, command in options.items():
        print(f"{option:<15}: {command}")

# 5. é…ç½®æ–‡ä»¶ç¤ºä¾‹
def config_file_example():
    """é…ç½®æ–‡ä»¶ç¤ºä¾‹"""
    print("\n=== YAMLé…ç½®æ–‡ä»¶ç¤ºä¾‹ ===")
    
    yaml_config = """
# config.yaml
model: resnet50
pretrained: true
num_classes: 1000
batch_size: 256
epochs: 90
lr: 0.1
opt: sgd
momentum: 0.9
weight_decay: 0.0001
sched: cosine
aa: rand-m9-mstd0.5-inc1
mixup: 0.2
cutmix: 1.0
drop_path: 0.1
amp: true
model_ema: true
model_ema_decay: 0.9999
"""
    
    print(yaml_config)
    print("ä½¿ç”¨é…ç½®æ–‡ä»¶:")
    print("python train.py /imagenet --config config.yaml")

# 6. å°æ•°æ®é›†ä¸“ç”¨è®­ç»ƒæ–¹æ¡ˆ (200å¼ å›¾ç‰‡)
def small_dataset_training_guide():
    """å°æ•°æ®é›†(200å¼ å›¾ç‰‡)ä¸“ç”¨è®­ç»ƒæŒ‡å—"""
    print("\n=== å°æ•°æ®é›†(200å¼ å›¾ç‰‡)ä¸“ç”¨è®­ç»ƒæ–¹æ¡ˆ ===")

    print("ğŸ¯ æ¨èæ–¹æ¡ˆ: è½»é‡çº§æ¨¡å‹ + å¼ºæ•°æ®å¢å¼º + é¢„è®­ç»ƒå¾®è°ƒ")

    # æ¨èæ¨¡å‹é€‰æ‹©
    recommended_models = {
        "é¦–é€‰æ¨¡å‹": {
            "æ¨¡å‹": "efficientnet_b0",
            "åŸå› ": "å‚æ•°å°‘(5.3M)ã€æ•ˆæœå¥½ã€é€‚åˆå°æ•°æ®é›†",
            "é¢„æœŸæ•ˆæœ": "åœ¨å°æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜ç§€"
        },
        "å¤‡é€‰æ¨¡å‹1": {
            "æ¨¡å‹": "mobilenetv3_small_100",
            "åŸå› ": "æè½»é‡(2.5Må‚æ•°)ã€è®­ç»ƒå¿«",
            "é¢„æœŸæ•ˆæœ": "å¿«é€Ÿæ”¶æ•›ï¼Œé€‚åˆå¿«é€ŸéªŒè¯"
        },
        "å¤‡é€‰æ¨¡å‹2": {
            "æ¨¡å‹": "resnet18",
            "åŸå› ": "ç»å…¸æ¶æ„ã€ç¨³å®šå¯é ",
            "é¢„æœŸæ•ˆæœ": "ç¨³å®šçš„åŸºçº¿æ€§èƒ½"
        }
    }

    for category, info in recommended_models.items():
        print(f"\n{category}:")
        for key, value in info.items():
            print(f"  {key}: {value}")

    # æœ€ä½³è®­ç»ƒå‘½ä»¤
    print("\nğŸš€ æœ€ä½³è®­ç»ƒå‘½ä»¤:")
    best_command = [
        "python train.py /path/to/your/dataset",
        "--model efficientnet_b0",
        "--pretrained",  # å¿…é¡»ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
        "--num-classes YOUR_CLASS_NUM",  # æ›¿æ¢ä¸ºæ‚¨çš„ç±»åˆ«æ•°
        "--batch-size 16",  # å°æ‰¹æ¬¡é¿å…è¿‡æ‹Ÿåˆ
        "--lr 0.001",  # è¾ƒå°å­¦ä¹ ç‡
        "--epochs 100",  # æ›´å¤šè½®æ¬¡
        "--opt adamw",  # AdamWä¼˜åŒ–å™¨
        "--weight-decay 0.01",  # æƒé‡è¡°å‡é˜²æ­¢è¿‡æ‹Ÿåˆ
        "--sched cosine",  # ä½™å¼¦å­¦ä¹ ç‡è°ƒåº¦
        "--warmup-epochs 5",  # é¢„çƒ­
        # å¼ºæ•°æ®å¢å¼º - å…³é”®!
        "--aa rand-m15-mstd0.5-inc1",  # å¼ºAutoAugment
        "--mixup 0.4",  # Mixupå¢å¼º
        "--cutmix 1.0",  # CutMixå¢å¼º
        "--reprob 0.3",  # Random Erasing
        "--drop-path 0.1",  # DropPathæ­£åˆ™åŒ–
        # å…¶ä»–é‡è¦è®¾ç½®
        "--amp",  # æ··åˆç²¾åº¦
        "--model-ema",  # æŒ‡æ•°ç§»åŠ¨å¹³å‡
        "--model-ema-decay 0.9999",
        "--patience 15",  # æ—©åœè€å¿ƒå€¼
        "--min-lr 1e-6"  # æœ€å°å­¦ä¹ ç‡
    ]

    command = " \\\n    ".join(best_command)
    print(f"  {command}")

    # æ•°æ®é›†åˆ’åˆ†å»ºè®®
    print("\nğŸ“Š æ•°æ®é›†åˆ’åˆ†å»ºè®®:")
    split_recommendations = {
        "è®­ç»ƒé›†": "160å¼  (80%)",
        "éªŒè¯é›†": "40å¼  (20%)",
        "å»ºè®®": "ç¡®ä¿æ¯ä¸ªç±»åˆ«è‡³å°‘æœ‰8-10å¼ å›¾ç‰‡ç”¨äºéªŒè¯"
    }

    for key, value in split_recommendations.items():
        print(f"  {key}: {value}")

    # å…³é”®æŠ€å·§
    print("\nğŸ’¡ å°æ•°æ®é›†è®­ç»ƒå…³é”®æŠ€å·§:")
    key_tips = [
        "1. å¿…é¡»ä½¿ç”¨é¢„è®­ç»ƒæƒé‡ (--pretrained)",
        "2. ä½¿ç”¨å¼ºæ•°æ®å¢å¼ºé˜²æ­¢è¿‡æ‹Ÿåˆ",
        "3. è¾ƒå°çš„æ‰¹æ¬¡å¤§å° (16-32)",
        "4. è¾ƒå°çš„å­¦ä¹ ç‡ (0.001-0.01)",
        "5. æ›´å¤šçš„è®­ç»ƒè½®æ¬¡ (100-200)",
        "6. å¯ç”¨æ—©åœæœºåˆ¶é˜²æ­¢è¿‡æ‹Ÿåˆ",
        "7. ä½¿ç”¨æ¨¡å‹EMAæé«˜ç¨³å®šæ€§",
        "8. ç›‘æ§è®­ç»ƒ/éªŒè¯æŸå¤±å·®å¼‚"
    ]

    for tip in key_tips:
        print(f"  {tip}")

def small_dataset_monitoring():
    """å°æ•°æ®é›†è®­ç»ƒç›‘æ§æŒ‡å—"""
    print("\n=== å°æ•°æ®é›†è®­ç»ƒç›‘æ§ ===")

    monitoring_points = {
        "è¿‡æ‹Ÿåˆæ£€æµ‹": [
            "è®­ç»ƒæŸå¤±æŒç»­ä¸‹é™ï¼ŒéªŒè¯æŸå¤±ä¸Šå‡",
            "è®­ç»ƒå‡†ç¡®ç‡ >> éªŒè¯å‡†ç¡®ç‡",
            "è§£å†³æ–¹æ¡ˆ: å¢å¼ºæ•°æ®å¢å¼ºã€å‡å°‘æ¨¡å‹å¤æ‚åº¦"
        ],

        "æ¬ æ‹Ÿåˆæ£€æµ‹": [
            "è®­ç»ƒå’ŒéªŒè¯æŸå¤±éƒ½å¾ˆé«˜",
            "å‡†ç¡®ç‡æå‡ç¼“æ…¢",
            "è§£å†³æ–¹æ¡ˆ: å¢åŠ æ¨¡å‹å¤æ‚åº¦ã€è°ƒæ•´å­¦ä¹ ç‡"
        ],

        "ç†æƒ³çŠ¶æ€": [
            "è®­ç»ƒå’ŒéªŒè¯æŸå¤±åŒæ­¥ä¸‹é™",
            "éªŒè¯å‡†ç¡®ç‡ç¨³æ­¥æå‡",
            "è®­ç»ƒ/éªŒè¯å‡†ç¡®ç‡å·®è· < 5%"
        ]
    }

    for status, indicators in monitoring_points.items():
        print(f"\n{status}:")
        for indicator in indicators:
            print(f"  â€¢ {indicator}")

def small_dataset_data_augmentation():
    """å°æ•°æ®é›†ä¸“ç”¨æ•°æ®å¢å¼ºç­–ç•¥"""
    print("\n=== å°æ•°æ®é›†ä¸“ç”¨æ•°æ®å¢å¼ºç­–ç•¥ ===")

    augmentation_levels = {
        "åŸºç¡€å¢å¼º (ä¿å®ˆ)": [
            "--hflip 0.5",
            "--color-jitter 0.3",
            "--aa rand-m7-mstd0.5",
            "--mixup 0.2",
            "--reprob 0.2"
        ],

        "å¼ºå¢å¼º (æ¨è)": [
            "--hflip 0.5",
            "--vflip 0.1",  # æ ¹æ®æ•°æ®ç‰¹æ€§è°ƒæ•´
            "--color-jitter 0.4",
            "--aa rand-m15-mstd0.5-inc1",
            "--mixup 0.4",
            "--cutmix 1.0",
            "--reprob 0.3",
            "--remode pixel"
        ],

        "æå¼ºå¢å¼º (æ•°æ®æå°‘æ—¶)": [
            "--hflip 0.5",
            "--vflip 0.2",
            "--color-jitter 0.5",
            "--aa rand-m20-mstd0.5-inc1",
            "--mixup 0.6",
            "--cutmix 1.2",
            "--reprob 0.4",
            "--trivial-augment"  # å¦‚æœæ”¯æŒ
        ]
    }

    for level, augs in augmentation_levels.items():
        print(f"\n{level}:")
        for aug in augs:
            print(f"  {aug}")

if __name__ == "__main__":
    basic_training_commands()
    training_parameters()
    training_scenarios()
    advanced_training_options()
    config_file_example()

    # æ–°å¢å°æ•°æ®é›†ä¸“ç”¨æŒ‡å—
    small_dataset_training_guide()
    small_dataset_monitoring()
    small_dataset_data_augmentation()

    print("\n=== è®­ç»ƒç›‘æ§ ===")
    print("1. TensorBoard: è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šè‡ªåŠ¨ç”Ÿæˆæ—¥å¿—")
    print("2. Wandb: æ·»åŠ  --experiment wandb_project_name")
    print("3. æ£€æŸ¥ç‚¹ä¿å­˜: è‡ªåŠ¨ä¿å­˜åœ¨ ./output/ ç›®å½•")
    print("4. æœ€ä½³æ¨¡å‹: æ ¹æ®éªŒè¯é›†æ€§èƒ½è‡ªåŠ¨ä¿å­˜")

    print("\n=== 200å¼ å›¾ç‰‡è®­ç»ƒæ€»ç»“ ===")
    print("ğŸ¯ æ ¸å¿ƒç­–ç•¥: é¢„è®­ç»ƒæ¨¡å‹ + å¼ºæ•°æ®å¢å¼º + å°å­¦ä¹ ç‡ + æ—©åœ")
    print("ğŸ“ˆ é¢„æœŸæ•ˆæœ: åœ¨å°æ•°æ®é›†ä¸Šä¹Ÿèƒ½è¾¾åˆ°ä¸é”™çš„åˆ†ç±»æ•ˆæœ")
    print("âš ï¸  æ³¨æ„äº‹é¡¹: å¯†åˆ‡ç›‘æ§è¿‡æ‹Ÿåˆï¼ŒåŠæ—¶è°ƒæ•´è¶…å‚æ•°")
