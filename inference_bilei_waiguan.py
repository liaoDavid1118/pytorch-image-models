#!/usr/bin/env python3
"""
bilei vs waiguan åˆ†ç±»æ¨¡å‹æ¨ç†è„šæœ¬
ä½¿ç”¨è®­ç»ƒå¥½çš„EfficientNet-B0æ¨¡å‹è¿›è¡Œå›¾åƒåˆ†ç±»
"""

import torch
import timm
from PIL import Image
import numpy as np
from pathlib import Path
import argparse

class BileiWaiguanClassifier:
    def __init__(self, model_path, device='cpu'):
        """
        åˆå§‹åŒ–åˆ†ç±»å™¨
        
        Args:
            model_path: æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„
            device: è®¡ç®—è®¾å¤‡ ('cpu' æˆ– 'cuda')
        """
        self.device = device
        self.class_names = ['bilei', 'waiguan']  # æ ¹æ®æ‚¨çš„æ•°æ®é›†ç±»åˆ«
        
        # åˆ›å»ºæ¨¡å‹
        self.model = timm.create_model('efficientnet_b0', num_classes=2)
        
        # åŠ è½½æƒé‡
        checkpoint = torch.load(model_path, map_location=device, weights_only=False)
        if 'state_dict' in checkpoint:
            state_dict = checkpoint['state_dict']
        elif 'model' in checkpoint:
            state_dict = checkpoint['model']
        else:
            state_dict = checkpoint
            
        self.model.load_state_dict(state_dict)
        self.model.eval()
        self.model.to(device)
        
        # è·å–æ•°æ®é¢„å¤„ç†é…ç½®
        self.data_config = timm.data.resolve_data_config({}, model=self.model)
        self.transform = timm.data.create_transform(**self.data_config, is_training=False)
        
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
        print(f"ğŸ“± è®¾å¤‡: {device}")
        print(f"ğŸ·ï¸  ç±»åˆ«: {self.class_names}")
        print(f"ğŸ“ è¾“å…¥å°ºå¯¸: {self.data_config['input_size']}")

    def predict_single(self, image_path):
        """
        å¯¹å•å¼ å›¾ç‰‡è¿›è¡Œé¢„æµ‹
        
        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            
        Returns:
            dict: åŒ…å«é¢„æµ‹ç»“æœçš„å­—å…¸
        """
        # åŠ è½½å’Œé¢„å¤„ç†å›¾ç‰‡
        image = Image.open(image_path).convert('RGB')
        input_tensor = self.transform(image).unsqueeze(0).to(self.device)
        
        # æ¨ç†
        with torch.no_grad():
            outputs = self.model(input_tensor)
            probabilities = torch.nn.functional.softmax(outputs, dim=1)
            confidence, predicted = torch.max(probabilities, 1)
            
        # æ ¼å¼åŒ–ç»“æœ
        result = {
            'image_path': str(image_path),
            'predicted_class': self.class_names[predicted.item()],
            'confidence': confidence.item(),
            'probabilities': {
                self.class_names[i]: prob.item() 
                for i, prob in enumerate(probabilities[0])
            }
        }
        
        return result

    def predict_batch(self, image_paths):
        """
        æ‰¹é‡é¢„æµ‹å¤šå¼ å›¾ç‰‡
        
        Args:
            image_paths: å›¾ç‰‡è·¯å¾„åˆ—è¡¨
            
        Returns:
            list: é¢„æµ‹ç»“æœåˆ—è¡¨
        """
        results = []
        for image_path in image_paths:
            try:
                result = self.predict_single(image_path)
                results.append(result)
                print(f"âœ… {Path(image_path).name}: {result['predicted_class']} ({result['confidence']:.3f})")
            except Exception as e:
                print(f"âŒ {Path(image_path).name}: å¤„ç†å¤±è´¥ - {e}")
                
        return results

    def predict_folder(self, folder_path, extensions=('.jpg', '.jpeg', '.png', '.bmp')):
        """
        é¢„æµ‹æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾ç‰‡
        
        Args:
            folder_path: æ–‡ä»¶å¤¹è·¯å¾„
            extensions: æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
            
        Returns:
            list: é¢„æµ‹ç»“æœåˆ—è¡¨
        """
        folder_path = Path(folder_path)
        image_paths = []
        
        for ext in extensions:
            image_paths.extend(folder_path.glob(f"*{ext}"))
            image_paths.extend(folder_path.glob(f"*{ext.upper()}"))
        
        if not image_paths:
            print(f"âš ï¸  åœ¨ {folder_path} ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
            return []
        
        print(f"ğŸ“ æ‰¾åˆ° {len(image_paths)} å¼ å›¾ç‰‡")
        return self.predict_batch(image_paths)

def main():
    parser = argparse.ArgumentParser(description="bilei vs waiguan å›¾åƒåˆ†ç±»æ¨ç†")
    parser.add_argument("--model", required=True, help="æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--input", required=True, help="è¾“å…¥å›¾ç‰‡è·¯å¾„æˆ–æ–‡ä»¶å¤¹è·¯å¾„")
    parser.add_argument("--device", default="cpu", help="è®¡ç®—è®¾å¤‡ (cpu/cuda)")
    parser.add_argument("--output", help="è¾“å‡ºç»“æœæ–‡ä»¶è·¯å¾„ (å¯é€‰)")
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–åˆ†ç±»å™¨
    classifier = BileiWaiguanClassifier(args.model, args.device)
    
    # æ‰§è¡Œé¢„æµ‹
    input_path = Path(args.input)
    
    if input_path.is_file():
        # å•å¼ å›¾ç‰‡é¢„æµ‹
        print(f"\nğŸ” é¢„æµ‹å•å¼ å›¾ç‰‡: {input_path}")
        result = classifier.predict_single(input_path)
        
        print(f"\nğŸ“Š é¢„æµ‹ç»“æœ:")
        print(f"ğŸ·ï¸  ç±»åˆ«: {result['predicted_class']}")
        print(f"ğŸ¯ ç½®ä¿¡åº¦: {result['confidence']:.3f}")
        print(f"ğŸ“ˆ è¯¦ç»†æ¦‚ç‡:")
        for class_name, prob in result['probabilities'].items():
            print(f"   {class_name}: {prob:.3f}")
            
        results = [result]
        
    elif input_path.is_dir():
        # æ–‡ä»¶å¤¹æ‰¹é‡é¢„æµ‹
        print(f"\nğŸ“ é¢„æµ‹æ–‡ä»¶å¤¹: {input_path}")
        results = classifier.predict_folder(input_path)
        
        # ç»Ÿè®¡ç»“æœ
        if results:
            bilei_count = sum(1 for r in results if r['predicted_class'] == 'bilei')
            waiguan_count = sum(1 for r in results if r['predicted_class'] == 'waiguan')
            avg_confidence = sum(r['confidence'] for r in results) / len(results)
            
            print(f"\nğŸ“Š æ‰¹é‡é¢„æµ‹ç»Ÿè®¡:")
            print(f"ğŸ“¸ æ€»å›¾ç‰‡æ•°: {len(results)}")
            print(f"ğŸ”µ bilei: {bilei_count} å¼ ")
            print(f"ğŸ”´ waiguan: {waiguan_count} å¼ ")
            print(f"ğŸ¯ å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}")
    else:
        print(f"âŒ è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {input_path}")
        return
    
    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    if args.output and results:
        import json
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {args.output}")

if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    print("ğŸ¯ bilei vs waiguan åˆ†ç±»å™¨")
    print("=" * 50)
    
    # å¦‚æœç›´æ¥è¿è¡Œï¼Œæ˜¾ç¤ºä½¿ç”¨è¯´æ˜
    import sys
    if len(sys.argv) == 1:
        print("ğŸ“– ä½¿ç”¨æ–¹æ³•:")
        print("1. é¢„æµ‹å•å¼ å›¾ç‰‡:")
        print("   python inference_bilei_waiguan.py --model model_best.pth.tar --input image.jpg")
        print()
        print("2. é¢„æµ‹æ–‡ä»¶å¤¹:")
        print("   python inference_bilei_waiguan.py --model model_best.pth.tar --input ./test_images/")
        print()
        print("3. ä¿å­˜ç»“æœ:")
        print("   python inference_bilei_waiguan.py --model model_best.pth.tar --input ./images/ --output results.json")
        print()
        print("ğŸ’¡ æç¤º: æ¨¡å‹æ–‡ä»¶è·¯å¾„ç¤ºä¾‹:")
        print("   ./output_bilei_waiguan/bilei_waiguan_classification/model_best.pth.tar")
    else:
        main()
