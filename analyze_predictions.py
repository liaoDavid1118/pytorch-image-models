#!/usr/bin/env python3
"""
é¢„æµ‹ç»“æœåˆ†æè„šæœ¬
åˆ†ææ‰¹é‡é¢„æµ‹çš„ç»“æœï¼Œç”Ÿæˆè¯¦ç»†çš„æ€§èƒ½æŠ¥å‘Š
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import json
from pathlib import Path
import argparse

def analyze_predictions(csv_file, true_class=None):
    """
    åˆ†æé¢„æµ‹ç»“æœ
    
    Args:
        csv_file: CSVç»“æœæ–‡ä»¶è·¯å¾„
        true_class: çœŸå®ç±»åˆ«åç§° (å¦‚æœå·²çŸ¥)
    """
    print(f"ğŸ” åˆ†æé¢„æµ‹ç»“æœ: {csv_file}")
    
    # è¯»å–CSVæ–‡ä»¶
    df = pd.read_csv(csv_file)
    
    print(f"ğŸ“Š æ€»é¢„æµ‹æ•°é‡: {len(df)}")
    
    # åŸºæœ¬ç»Ÿè®¡
    print("\nğŸ“ˆ åŸºæœ¬ç»Ÿè®¡:")
    print(f"  å¹³å‡ç½®ä¿¡åº¦: {df['confidence'].mean():.4f}")
    print(f"  ç½®ä¿¡åº¦æ ‡å‡†å·®: {df['confidence'].std():.4f}")
    print(f"  æœ€é«˜ç½®ä¿¡åº¦: {df['confidence'].max():.4f}")
    print(f"  æœ€ä½ç½®ä¿¡åº¦: {df['confidence'].min():.4f}")
    print(f"  å¹³å‡æ¨ç†æ—¶é—´: {df['inference_time_ms'].mean():.2f}ms")
    
    # ç±»åˆ«åˆ†å¸ƒ
    print("\nğŸ·ï¸  é¢„æµ‹ç±»åˆ«åˆ†å¸ƒ:")
    class_counts = df['predicted_class'].value_counts()
    for class_name, count in class_counts.items():
        percentage = (count / len(df)) * 100
        print(f"  {class_name}: {count} å¼  ({percentage:.1f}%)")
    
    # å¦‚æœæä¾›äº†çœŸå®ç±»åˆ«ï¼Œè®¡ç®—å‡†ç¡®ç‡
    if true_class:
        correct_predictions = df['predicted_class'] == true_class
        accuracy = correct_predictions.sum() / len(df)
        print(f"\nğŸ¯ {true_class} ç±»åˆ«å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy*100:.2f}%)")
        
        # é”™è¯¯é¢„æµ‹åˆ†æ
        wrong_predictions = df[~correct_predictions]
        if len(wrong_predictions) > 0:
            print(f"\nâŒ é”™è¯¯é¢„æµ‹åˆ†æ ({len(wrong_predictions)} å¼ ):")
            wrong_class_counts = wrong_predictions['predicted_class'].value_counts()
            for class_name, count in wrong_class_counts.items():
                percentage = (count / len(wrong_predictions)) * 100
                print(f"  è¯¯åˆ†ç±»ä¸º {class_name}: {count} å¼  ({percentage:.1f}%)")
            
            # æ˜¾ç¤ºç½®ä¿¡åº¦æœ€ä½çš„é”™è¯¯é¢„æµ‹
            print(f"\nğŸ” ç½®ä¿¡åº¦æœ€ä½çš„é”™è¯¯é¢„æµ‹:")
            low_conf_wrong = wrong_predictions.nsmallest(5, 'confidence')
            for _, row in low_conf_wrong.iterrows():
                print(f"  {row['image_name']}: {row['predicted_class']} (ç½®ä¿¡åº¦: {row['confidence']:.4f})")
    
    # ç½®ä¿¡åº¦åˆ†å¸ƒåˆ†æ
    print(f"\nğŸ“Š ç½®ä¿¡åº¦åˆ†å¸ƒ:")
    confidence_ranges = [
        (0.9, 1.0, "éå¸¸é«˜ (0.9-1.0)"),
        (0.8, 0.9, "é«˜ (0.8-0.9)"),
        (0.7, 0.8, "ä¸­ç­‰ (0.7-0.8)"),
        (0.6, 0.7, "è¾ƒä½ (0.6-0.7)"),
        (0.0, 0.6, "ä½ (0.0-0.6)")
    ]
    
    for min_conf, max_conf, label in confidence_ranges:
        count = len(df[(df['confidence'] >= min_conf) & (df['confidence'] < max_conf)])
        percentage = (count / len(df)) * 100
        print(f"  {label}: {count} å¼  ({percentage:.1f}%)")
    
    # ç”Ÿæˆè¯¦ç»†åˆ†ææŠ¥å‘Š
    analysis_report = {
        "file_analyzed": csv_file,
        "total_predictions": len(df),
        "true_class": true_class,
        "statistics": {
            "mean_confidence": float(df['confidence'].mean()),
            "std_confidence": float(df['confidence'].std()),
            "max_confidence": float(df['confidence'].max()),
            "min_confidence": float(df['confidence'].min()),
            "mean_inference_time_ms": float(df['inference_time_ms'].mean())
        },
        "class_distribution": class_counts.to_dict(),
        "confidence_distribution": {}
    }
    
    # æ·»åŠ ç½®ä¿¡åº¦åˆ†å¸ƒåˆ°æŠ¥å‘Š
    for min_conf, max_conf, label in confidence_ranges:
        count = len(df[(df['confidence'] >= min_conf) & (df['confidence'] < max_conf)])
        analysis_report["confidence_distribution"][label] = {
            "count": count,
            "percentage": (count / len(df)) * 100
        }
    
    # å¦‚æœæœ‰çœŸå®ç±»åˆ«ï¼Œæ·»åŠ å‡†ç¡®ç‡ä¿¡æ¯
    if true_class:
        correct_predictions = df['predicted_class'] == true_class
        accuracy = correct_predictions.sum() / len(df)
        analysis_report["accuracy"] = {
            "overall": float(accuracy),
            "correct_predictions": int(correct_predictions.sum()),
            "wrong_predictions": int((~correct_predictions).sum())
        }
        
        # é”™è¯¯é¢„æµ‹åˆ†æ
        wrong_predictions = df[~correct_predictions]
        if len(wrong_predictions) > 0:
            wrong_class_counts = wrong_predictions['predicted_class'].value_counts()
            analysis_report["error_analysis"] = {
                "misclassified_as": wrong_class_counts.to_dict(),
                "lowest_confidence_errors": []
            }
            
            # æ·»åŠ ç½®ä¿¡åº¦æœ€ä½çš„é”™è¯¯é¢„æµ‹
            low_conf_wrong = wrong_predictions.nsmallest(5, 'confidence')
            for _, row in low_conf_wrong.iterrows():
                analysis_report["error_analysis"]["lowest_confidence_errors"].append({
                    "image_name": row['image_name'],
                    "predicted_class": row['predicted_class'],
                    "confidence": float(row['confidence'])
                })
    
    # ä¿å­˜åˆ†ææŠ¥å‘Š
    report_file = csv_file.replace('.csv', '_analysis.json')
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(analysis_report, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ è¯¦ç»†åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    
    return analysis_report

def create_visualization(csv_file, true_class=None):
    """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
    print(f"\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    
    df = pd.read_csv(csv_file)
    
    # è®¾ç½®ä¸­æ–‡å­—ä½“
    plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False
    
    # åˆ›å»ºå­å›¾
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle(f'é¢„æµ‹ç»“æœåˆ†æ - {Path(csv_file).stem}', fontsize=16, fontweight='bold')
    
    # 1. ç±»åˆ«åˆ†å¸ƒé¥¼å›¾
    class_counts = df['predicted_class'].value_counts()
    axes[0, 0].pie(class_counts.values, labels=class_counts.index, autopct='%1.1f%%', startangle=90)
    axes[0, 0].set_title('é¢„æµ‹ç±»åˆ«åˆ†å¸ƒ')
    
    # 2. ç½®ä¿¡åº¦åˆ†å¸ƒç›´æ–¹å›¾
    axes[0, 1].hist(df['confidence'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')
    axes[0, 1].set_xlabel('ç½®ä¿¡åº¦')
    axes[0, 1].set_ylabel('æ•°é‡')
    axes[0, 1].set_title('ç½®ä¿¡åº¦åˆ†å¸ƒ')
    axes[0, 1].axvline(df['confidence'].mean(), color='red', linestyle='--', 
                       label=f'å¹³å‡å€¼: {df["confidence"].mean():.3f}')
    axes[0, 1].legend()
    
    # 3. æ¨ç†æ—¶é—´åˆ†å¸ƒ
    axes[1, 0].hist(df['inference_time_ms'], bins=20, alpha=0.7, color='lightgreen', edgecolor='black')
    axes[1, 0].set_xlabel('æ¨ç†æ—¶é—´ (ms)')
    axes[1, 0].set_ylabel('æ•°é‡')
    axes[1, 0].set_title('æ¨ç†æ—¶é—´åˆ†å¸ƒ')
    axes[1, 0].axvline(df['inference_time_ms'].mean(), color='red', linestyle='--',
                       label=f'å¹³å‡å€¼: {df["inference_time_ms"].mean():.1f}ms')
    axes[1, 0].legend()
    
    # 4. ç½®ä¿¡åº¦ vs ç±»åˆ«ç®±çº¿å›¾
    df_melted = df.melt(id_vars=['predicted_class'], 
                        value_vars=['confidence'], 
                        var_name='metric', value_name='value')
    sns.boxplot(data=df_melted, x='predicted_class', y='value', ax=axes[1, 1])
    axes[1, 1].set_xlabel('é¢„æµ‹ç±»åˆ«')
    axes[1, 1].set_ylabel('ç½®ä¿¡åº¦')
    axes[1, 1].set_title('å„ç±»åˆ«ç½®ä¿¡åº¦åˆ†å¸ƒ')
    axes[1, 1].tick_params(axis='x', rotation=45)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    plot_file = csv_file.replace('.csv', '_analysis.png')
    plt.savefig(plot_file, dpi=300, bbox_inches='tight')
    print(f"ğŸ“ˆ å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜: {plot_file}")
    
    plt.show()

def main():
    parser = argparse.ArgumentParser(description='é¢„æµ‹ç»“æœåˆ†æå·¥å…·')
    parser.add_argument('--csv', required=True, help='CSVç»“æœæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--true-class', help='çœŸå®ç±»åˆ«åç§°')
    parser.add_argument('--plot', action='store_true', help='ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨')
    
    args = parser.parse_args()
    
    # åˆ†æé¢„æµ‹ç»“æœ
    analysis_report = analyze_predictions(args.csv, args.true_class)
    
    # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
    if args.plot:
        create_visualization(args.csv, args.true_class)
    
    print(f"\nğŸ‰ åˆ†æå®Œæˆ!")

if __name__ == '__main__':
    main()
