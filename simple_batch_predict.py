#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆæ‰¹é‡é¢„æµ‹è„šæœ¬
å¿«é€Ÿé¢„æµ‹æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾ç‰‡å¹¶ç”Ÿæˆç»“æœæŠ¥å‘Š
"""

import torch
import timm
from PIL import Image
from pathlib import Path
import pandas as pd
from tqdm import tqdm
import time
from datetime import datetime

def load_model(model_path, device='auto'):
    """åŠ è½½æ¨¡å‹"""
    if device == 'auto':
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    print(f"ğŸš€ åŠ è½½æ¨¡å‹...")
    print(f"ğŸ“± è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ¨¡å‹
    model = timm.create_model('efficientnet_b0', num_classes=6)
    
    # åŠ è½½æƒé‡
    checkpoint = torch.load(model_path, map_location=device, weights_only=False)
    if 'state_dict' in checkpoint:
        state_dict = checkpoint['state_dict']
    else:
        state_dict = checkpoint
    
    model.load_state_dict(state_dict)
    model.eval()
    model.to(device)
    
    # æ•°æ®é¢„å¤„ç†
    data_config = timm.data.resolve_data_config({}, model=model)
    transform = timm.data.create_transform(**data_config, is_training=False)
    
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
    return model, transform, device

def predict_folder(model, transform, device, folder_path, output_file=None):
    """é¢„æµ‹æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾ç‰‡"""
    
    # ç±»åˆ«åç§°
    class_names = ['bilei', 'fuban', 'genbu', 'mengpi', 'qianhou', 'waiguan']
    
    # æ”¶é›†å›¾ç‰‡æ–‡ä»¶
    folder_path = Path(folder_path)
    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']
    image_paths = []
    
    for ext in image_extensions:
        image_paths.extend(folder_path.glob(f"*{ext}"))
        image_paths.extend(folder_path.glob(f"*{ext.upper()}"))

    # å»é™¤é‡å¤æ–‡ä»¶ (Windowsç³»ç»Ÿä¸åŒºåˆ†å¤§å°å†™ä¼šå¯¼è‡´é‡å¤)
    image_paths = list(set(image_paths))

    if not image_paths:
        print(f"âŒ åœ¨ {folder_path} ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
        return

    print(f"ğŸ“ æ‰¾åˆ° {len(image_paths)} å¼ å›¾ç‰‡")
    
    # æ‰¹é‡é¢„æµ‹
    results = []
    class_counts = {}
    total_time = 0
    
    for image_path in tqdm(image_paths, desc="é¢„æµ‹è¿›åº¦"):
        try:
            # åŠ è½½å›¾ç‰‡
            image = Image.open(image_path).convert('RGB')
            input_tensor = transform(image).unsqueeze(0).to(device)
            
            # é¢„æµ‹
            start_time = time.time()
            with torch.no_grad():
                outputs = model(input_tensor)
                probabilities = torch.nn.functional.softmax(outputs, dim=1)
                confidence, predicted = torch.max(probabilities, 1)
            
            inference_time = (time.time() - start_time) * 1000
            total_time += inference_time
            
            # è®°å½•ç»“æœ
            predicted_class = class_names[predicted.item()]
            class_counts[predicted_class] = class_counts.get(predicted_class, 0) + 1
            
            result = {
                'image_name': image_path.name,
                'predicted_class': predicted_class,
                'confidence': f"{confidence.item():.3f}",
                'inference_time_ms': f"{inference_time:.1f}"
            }
            
            # æ·»åŠ å„ç±»åˆ«æ¦‚ç‡
            for i, class_name in enumerate(class_names):
                result[f'prob_{class_name}'] = f"{probabilities[0][i].item():.3f}"
            
            results.append(result)
            
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥ {image_path.name}: {e}")
            results.append({
                'image_name': image_path.name,
                'error': str(e)
            })
    
    # æ˜¾ç¤ºç»Ÿè®¡ç»“æœ
    print(f"\nğŸ“Š é¢„æµ‹å®Œæˆç»Ÿè®¡:")
    print(f"ğŸ“¸ æ€»å›¾ç‰‡æ•°: {len(image_paths)}")
    print(f"âœ… æˆåŠŸé¢„æµ‹: {len([r for r in results if 'error' not in r])}")
    print(f"âŒ å¤±è´¥é¢„æµ‹: {len([r for r in results if 'error' in r])}")
    print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.1f}ms")
    print(f"âš¡ å¹³å‡é€Ÿåº¦: {total_time/len(image_paths):.1f}ms/å¼ ")
    
    print(f"\nğŸ·ï¸  ç±»åˆ«åˆ†å¸ƒ:")
    for class_name, count in class_counts.items():
        percentage = count / len([r for r in results if 'error' not in r]) * 100
        print(f"   {class_name}: {count} å¼  ({percentage:.1f}%)")
    
    # ä¿å­˜ç»“æœ
    if output_file:
        df = pd.DataFrame(results)
        
        if output_file.endswith('.csv'):
            df.to_csv(output_file, index=False, encoding='utf-8-sig')
        elif output_file.endswith('.xlsx'):
            df.to_excel(output_file, index=False)
        else:
            # é»˜è®¤ä¿å­˜ä¸ºCSV
            output_file = output_file + '.csv'
            df.to_csv(output_file, index=False, encoding='utf-8-sig')
        
        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜: {output_file}")
    
    return results, class_counts

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ 6ç±»åˆ«å›¾åƒåˆ†ç±»æ‰¹é‡é¢„æµ‹å·¥å…·")
    print("=" * 50)
    
    # é…ç½®å‚æ•° (å¯ä»¥æ ¹æ®éœ€è¦ä¿®æ”¹)
    MODEL_PATH = "./output_6class_gpu/six_class_gpu_training/model_best.pth.tar"
    INPUT_FOLDER = input("è¯·è¾“å…¥å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„: ").strip()
    OUTPUT_FILE = input("è¯·è¾“å…¥è¾“å‡ºæ–‡ä»¶å (å¯é€‰ï¼Œç›´æ¥å›è½¦è·³è¿‡): ").strip()
    
    if not INPUT_FOLDER:
        print("âŒ è¯·æä¾›å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„")
        return
    
    if not Path(INPUT_FOLDER).exists():
        print(f"âŒ æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {INPUT_FOLDER}")
        return
    
    if not Path(MODEL_PATH).exists():
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {MODEL_PATH}")
        print("è¯·ç¡®ä¿å·²å®Œæˆæ¨¡å‹è®­ç»ƒ")
        return
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šè¾“å‡ºæ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤åç§°
    if not OUTPUT_FILE:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        OUTPUT_FILE = f"prediction_results_{timestamp}.csv"
    
    try:
        # åŠ è½½æ¨¡å‹
        model, transform, device = load_model(MODEL_PATH)
        
        # æ‰§è¡Œé¢„æµ‹
        results, class_counts = predict_folder(model, transform, device, INPUT_FOLDER, OUTPUT_FILE)
        
        print(f"\nğŸ‰ æ‰¹é‡é¢„æµ‹å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")

if __name__ == "__main__":
    main()
