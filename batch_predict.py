#!/usr/bin/env python3
"""
æ‰¹é‡é¢„æµ‹è„šæœ¬ - 6ç±»åˆ«å›¾åƒåˆ†ç±»
æ”¯æŒå•å¼ å›¾ç‰‡ã€æ–‡ä»¶å¤¹æ‰¹é‡é¢„æµ‹ã€CSVå¯¼å‡ºç­‰åŠŸèƒ½
"""

import torch
import timm
from PIL import Image
import numpy as np
from pathlib import Path
import argparse
import json
import csv
import time
from datetime import datetime
import pandas as pd
from tqdm import tqdm
import os

class BatchPredictor:
    def __init__(self, model_path, device='auto', num_classes=6):
        """
        åˆå§‹åŒ–æ‰¹é‡é¢„æµ‹å™¨
        
        Args:
            model_path: æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„
            device: è®¡ç®—è®¾å¤‡ ('auto', 'cpu', 'cuda')
            num_classes: ç±»åˆ«æ•°é‡
        """
        # è‡ªåŠ¨é€‰æ‹©è®¾å¤‡
        if device == 'auto':
            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        else:
            self.device = device
            
        self.num_classes = num_classes
        
        # 6ç±»åˆ«åç§°
        self.class_names = ['bilei', 'fuban', 'genbu', 'mengpi', 'qianhou', 'waiguan']
        
        print(f"ğŸš€ åˆå§‹åŒ–æ‰¹é‡é¢„æµ‹å™¨...")
        print(f"ğŸ“± è®¾å¤‡: {self.device}")
        print(f"ğŸ·ï¸  ç±»åˆ«æ•°: {num_classes}")
        print(f"ğŸ“‚ æ¨¡å‹è·¯å¾„: {model_path}")
        
        # åˆ›å»ºæ¨¡å‹
        self.model = timm.create_model('efficientnet_b0', num_classes=num_classes)
        
        # åŠ è½½æƒé‡
        checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)
        if 'state_dict' in checkpoint:
            state_dict = checkpoint['state_dict']
        elif 'model' in checkpoint:
            state_dict = checkpoint['model']
        else:
            state_dict = checkpoint
            
        self.model.load_state_dict(state_dict)
        self.model.eval()
        self.model.to(self.device)
        
        # è·å–æ•°æ®é¢„å¤„ç†é…ç½®
        self.data_config = timm.data.resolve_data_config({}, model=self.model)
        self.transform = timm.data.create_transform(**self.data_config, is_training=False)
        
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
        print(f"ğŸ“ è¾“å…¥å°ºå¯¸: {self.data_config['input_size']}")

    def predict_single(self, image_path):
        """
        é¢„æµ‹å•å¼ å›¾ç‰‡
        
        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            
        Returns:
            dict: é¢„æµ‹ç»“æœ
        """
        try:
            # åŠ è½½å’Œé¢„å¤„ç†å›¾ç‰‡
            image = Image.open(image_path).convert('RGB')
            input_tensor = self.transform(image).unsqueeze(0).to(self.device)
            
            # æ¨ç†
            start_time = time.time()
            with torch.no_grad():
                outputs = self.model(input_tensor)
                probabilities = torch.nn.functional.softmax(outputs, dim=1)
                confidence, predicted = torch.max(probabilities, 1)
            inference_time = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            
            # æ ¼å¼åŒ–ç»“æœ
            result = {
                'image_path': str(image_path),
                'image_name': Path(image_path).name,
                'predicted_class': self.class_names[predicted.item()],
                'predicted_index': predicted.item(),
                'confidence': float(confidence.item()),
                'inference_time_ms': float(inference_time),
                'probabilities': {
                    self.class_names[i]: float(prob.item()) 
                    for i, prob in enumerate(probabilities[0])
                },
                'timestamp': datetime.now().isoformat()
            }
            
            return result
            
        except Exception as e:
            return {
                'image_path': str(image_path),
                'image_name': Path(image_path).name,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }

    def predict_folder(self, folder_path, extensions=('.jpg', '.jpeg', '.png', '.bmp', '.tiff')):
        """
        é¢„æµ‹æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾ç‰‡
        
        Args:
            folder_path: æ–‡ä»¶å¤¹è·¯å¾„
            extensions: æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
            
        Returns:
            list: é¢„æµ‹ç»“æœåˆ—è¡¨
        """
        folder_path = Path(folder_path)
        image_paths = []
        
        # æ”¶é›†æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
        for ext in extensions:
            image_paths.extend(folder_path.glob(f"*{ext}"))
            image_paths.extend(folder_path.glob(f"*{ext.upper()}"))

        # å»é™¤é‡å¤æ–‡ä»¶ (Windowsç³»ç»Ÿä¸åŒºåˆ†å¤§å°å†™ä¼šå¯¼è‡´é‡å¤)
        image_paths = list(set(image_paths))

        if not image_paths:
            print(f"âš ï¸  åœ¨ {folder_path} ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
            return []

        print(f"ğŸ“ æ‰¾åˆ° {len(image_paths)} å¼ å›¾ç‰‡")
        
        # æ‰¹é‡é¢„æµ‹
        results = []
        successful = 0
        failed = 0
        
        for image_path in tqdm(image_paths, desc="é¢„æµ‹è¿›åº¦"):
            result = self.predict_single(image_path)
            results.append(result)
            
            if 'error' in result:
                failed += 1
            else:
                successful += 1
        
        print(f"âœ… é¢„æµ‹å®Œæˆ: æˆåŠŸ {successful} å¼ , å¤±è´¥ {failed} å¼ ")
        return results

    def predict_recursive(self, root_path, extensions=('.jpg', '.jpeg', '.png', '.bmp', '.tiff')):
        """
        é€’å½’é¢„æµ‹ç›®å½•åŠå­ç›®å½•ä¸­çš„æ‰€æœ‰å›¾ç‰‡
        
        Args:
            root_path: æ ¹ç›®å½•è·¯å¾„
            extensions: æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
            
        Returns:
            list: é¢„æµ‹ç»“æœåˆ—è¡¨
        """
        root_path = Path(root_path)
        image_paths = []
        
        # é€’å½’æ”¶é›†æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
        for ext in extensions:
            image_paths.extend(root_path.rglob(f"*{ext}"))
            image_paths.extend(root_path.rglob(f"*{ext.upper()}"))

        # å»é™¤é‡å¤æ–‡ä»¶ (Windowsç³»ç»Ÿä¸åŒºåˆ†å¤§å°å†™ä¼šå¯¼è‡´é‡å¤)
        image_paths = list(set(image_paths))

        if not image_paths:
            print(f"âš ï¸  åœ¨ {root_path} åŠå…¶å­ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
            return []

        print(f"ğŸ“ é€’å½’æ‰¾åˆ° {len(image_paths)} å¼ å›¾ç‰‡")
        
        # æ‰¹é‡é¢„æµ‹
        results = []
        successful = 0
        failed = 0
        
        for image_path in tqdm(image_paths, desc="é€’å½’é¢„æµ‹è¿›åº¦"):
            result = self.predict_single(image_path)
            results.append(result)
            
            if 'error' in result:
                failed += 1
            else:
                successful += 1
        
        print(f"âœ… é€’å½’é¢„æµ‹å®Œæˆ: æˆåŠŸ {successful} å¼ , å¤±è´¥ {failed} å¼ ")
        return results

    def save_results(self, results, output_path, format='json'):
        """
        ä¿å­˜é¢„æµ‹ç»“æœ
        
        Args:
            results: é¢„æµ‹ç»“æœåˆ—è¡¨
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            format: è¾“å‡ºæ ¼å¼ ('json', 'csv', 'excel')
        """
        output_path = Path(output_path)
        
        if format.lower() == 'json':
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ JSONç»“æœå·²ä¿å­˜: {output_path}")
            
        elif format.lower() == 'csv':
            # å‡†å¤‡CSVæ•°æ®
            csv_data = []
            for result in results:
                if 'error' not in result:
                    row = {
                        'image_name': result['image_name'],
                        'image_path': result['image_path'],
                        'predicted_class': result['predicted_class'],
                        'confidence': result['confidence'],
                        'inference_time_ms': result['inference_time_ms'],
                        'timestamp': result['timestamp']
                    }
                    # æ·»åŠ å„ç±»åˆ«æ¦‚ç‡
                    for class_name, prob in result['probabilities'].items():
                        row[f'prob_{class_name}'] = prob
                    csv_data.append(row)
                else:
                    csv_data.append({
                        'image_name': result['image_name'],
                        'image_path': result['image_path'],
                        'error': result['error'],
                        'timestamp': result['timestamp']
                    })
            
            # å†™å…¥CSV
            if csv_data:
                df = pd.DataFrame(csv_data)
                df.to_csv(output_path, index=False, encoding='utf-8-sig')
                print(f"ğŸ’¾ CSVç»“æœå·²ä¿å­˜: {output_path}")
            
        elif format.lower() == 'excel':
            # å‡†å¤‡Excelæ•°æ®
            excel_data = []
            for result in results:
                if 'error' not in result:
                    row = {
                        'image_name': result['image_name'],
                        'image_path': result['image_path'],
                        'predicted_class': result['predicted_class'],
                        'confidence': result['confidence'],
                        'inference_time_ms': result['inference_time_ms'],
                        'timestamp': result['timestamp']
                    }
                    # æ·»åŠ å„ç±»åˆ«æ¦‚ç‡
                    for class_name, prob in result['probabilities'].items():
                        row[f'prob_{class_name}'] = prob
                    excel_data.append(row)
            
            if excel_data:
                df = pd.DataFrame(excel_data)
                df.to_excel(output_path, index=False)
                print(f"ğŸ’¾ Excelç»“æœå·²ä¿å­˜: {output_path}")

    def generate_summary_report(self, results):
        """
        ç”Ÿæˆé¢„æµ‹ç»“æœç»Ÿè®¡æŠ¥å‘Š
        
        Args:
            results: é¢„æµ‹ç»“æœåˆ—è¡¨
            
        Returns:
            dict: ç»Ÿè®¡æŠ¥å‘Š
        """
        successful_results = [r for r in results if 'error' not in r]
        failed_results = [r for r in results if 'error' in r]
        
        if not successful_results:
            return {
                'total_images': len(results),
                'successful': 0,
                'failed': len(failed_results),
                'error': 'æ²¡æœ‰æˆåŠŸé¢„æµ‹çš„å›¾ç‰‡'
            }
        
        # ç»Ÿè®¡å„ç±»åˆ«æ•°é‡
        class_counts = {}
        confidences = []
        inference_times = []
        
        for result in successful_results:
            predicted_class = result['predicted_class']
            class_counts[predicted_class] = class_counts.get(predicted_class, 0) + 1
            confidences.append(result['confidence'])
            inference_times.append(result['inference_time_ms'])
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        report = {
            'summary': {
                'total_images': len(results),
                'successful_predictions': len(successful_results),
                'failed_predictions': len(failed_results),
                'success_rate': len(successful_results) / len(results) * 100
            },
            'class_distribution': class_counts,
            'performance': {
                'avg_confidence': np.mean(confidences),
                'min_confidence': np.min(confidences),
                'max_confidence': np.max(confidences),
                'avg_inference_time_ms': np.mean(inference_times),
                'total_inference_time_ms': np.sum(inference_times)
            },
            'timestamp': datetime.now().isoformat()
        }
        
        return report

def main():
    parser = argparse.ArgumentParser(description="6ç±»åˆ«å›¾åƒåˆ†ç±»æ‰¹é‡é¢„æµ‹è„šæœ¬")
    parser.add_argument("--model", required=True, help="æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--input", required=True, help="è¾“å…¥å›¾ç‰‡è·¯å¾„æˆ–æ–‡ä»¶å¤¹è·¯å¾„")
    parser.add_argument("--output", help="è¾“å‡ºç»“æœæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--format", choices=['json', 'csv', 'excel'], default='json', help="è¾“å‡ºæ ¼å¼")
    parser.add_argument("--device", choices=['auto', 'cpu', 'cuda'], default='auto', help="è®¡ç®—è®¾å¤‡")
    parser.add_argument("--recursive", action='store_true', help="é€’å½’å¤„ç†å­ç›®å½•")
    parser.add_argument("--report", action='store_true', help="ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š")
    
    args = parser.parse_args()
    
    print("ğŸ¯ 6ç±»åˆ«å›¾åƒåˆ†ç±»æ‰¹é‡é¢„æµ‹")
    print("=" * 50)
    
    # åˆå§‹åŒ–é¢„æµ‹å™¨
    predictor = BatchPredictor(args.model, args.device)
    
    # æ‰§è¡Œé¢„æµ‹
    input_path = Path(args.input)
    
    if input_path.is_file():
        # å•å¼ å›¾ç‰‡é¢„æµ‹
        print(f"\nğŸ” é¢„æµ‹å•å¼ å›¾ç‰‡: {input_path}")
        result = predictor.predict_single(input_path)
        
        if 'error' not in result:
            print(f"\nğŸ“Š é¢„æµ‹ç»“æœ:")
            print(f"ğŸ·ï¸  ç±»åˆ«: {result['predicted_class']}")
            print(f"ğŸ¯ ç½®ä¿¡åº¦: {result['confidence']:.3f}")
            print(f"â±ï¸  æ¨ç†æ—¶é—´: {result['inference_time_ms']:.1f}ms")
            print(f"ğŸ“ˆ è¯¦ç»†æ¦‚ç‡:")
            for class_name, prob in result['probabilities'].items():
                print(f"   {class_name}: {prob:.3f}")
        else:
            print(f"âŒ é¢„æµ‹å¤±è´¥: {result['error']}")
            
        results = [result]
        
    elif input_path.is_dir():
        # æ–‡ä»¶å¤¹æ‰¹é‡é¢„æµ‹
        if args.recursive:
            print(f"\nğŸ“ é€’å½’é¢„æµ‹ç›®å½•: {input_path}")
            results = predictor.predict_recursive(input_path)
        else:
            print(f"\nğŸ“ é¢„æµ‹æ–‡ä»¶å¤¹: {input_path}")
            results = predictor.predict_folder(input_path)
    else:
        print(f"âŒ è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {input_path}")
        return
    
    # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
    if args.report and results:
        print(f"\nğŸ“Š ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š...")
        report = predictor.generate_summary_report(results)
        
        print(f"\nğŸ“ˆ é¢„æµ‹ç»Ÿè®¡:")
        print(f"ğŸ“¸ æ€»å›¾ç‰‡æ•°: {report['summary']['total_images']}")
        print(f"âœ… æˆåŠŸé¢„æµ‹: {report['summary']['successful_predictions']}")
        print(f"âŒ å¤±è´¥é¢„æµ‹: {report['summary']['failed_predictions']}")
        print(f"ğŸ“Š æˆåŠŸç‡: {report['summary']['success_rate']:.1f}%")
        
        if 'class_distribution' in report:
            print(f"\nğŸ·ï¸  ç±»åˆ«åˆ†å¸ƒ:")
            for class_name, count in report['class_distribution'].items():
                print(f"   {class_name}: {count} å¼ ")
        
        if 'performance' in report:
            print(f"\nâš¡ æ€§èƒ½ç»Ÿè®¡:")
            print(f"   å¹³å‡ç½®ä¿¡åº¦: {report['performance']['avg_confidence']:.3f}")
            print(f"   å¹³å‡æ¨ç†æ—¶é—´: {report['performance']['avg_inference_time_ms']:.1f}ms")
            print(f"   æ€»æ¨ç†æ—¶é—´: {report['performance']['total_inference_time_ms']:.1f}ms")
    
    # ä¿å­˜ç»“æœ
    if args.output and results:
        predictor.save_results(results, args.output, args.format)
        
        # åŒæ—¶ä¿å­˜ç»Ÿè®¡æŠ¥å‘Š
        if args.report:
            report_path = Path(args.output).with_suffix('.report.json')
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            print(f"ğŸ“Š ç»Ÿè®¡æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

if __name__ == "__main__":
    main()
