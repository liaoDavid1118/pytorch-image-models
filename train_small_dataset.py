#!/usr/bin/env python3
"""
200å¼ å›¾ç‰‡å°æ•°æ®é›†ä¸“ç”¨è®­ç»ƒè„šæœ¬
é’ˆå¯¹å°æ•°æ®é›†ä¼˜åŒ–çš„å®Œæ•´è®­ç»ƒæµç¨‹
"""

import os
import sys
import subprocess
import argparse
from datetime import datetime
from pathlib import Path

def check_dataset_structure(dataset_path):
    """æ£€æŸ¥æ•°æ®é›†ç»“æ„"""
    dataset_path = Path(dataset_path)
    
    if not dataset_path.exists():
        raise ValueError(f"æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {dataset_path}")
    
    train_dir = dataset_path / "train"
    val_dir = dataset_path / "val"
    
    if not train_dir.exists():
        raise ValueError(f"ç¼ºå°‘è®­ç»ƒé›†ç›®å½•: {train_dir}")
    
    if not val_dir.exists():
        raise ValueError(f"ç¼ºå°‘éªŒè¯é›†ç›®å½•: {val_dir}")
    
    # ç»Ÿè®¡æ•°æ®é›†ä¿¡æ¯
    train_classes = [d.name for d in train_dir.iterdir() if d.is_dir()]
    val_classes = [d.name for d in val_dir.iterdir() if d.is_dir()]
    
    print(f"âœ… æ•°æ®é›†ç»“æ„æ£€æŸ¥é€šè¿‡")
    print(f"ğŸ“Š è®­ç»ƒé›†ç±»åˆ«: {len(train_classes)} ä¸ª")
    print(f"ğŸ“Š éªŒè¯é›†ç±»åˆ«: {len(val_classes)} ä¸ª")
    print(f"ğŸ“Š ç±»åˆ«åˆ—è¡¨: {train_classes}")
    
    # ç»Ÿè®¡å›¾ç‰‡æ•°é‡
    total_train = 0
    total_val = 0
    
    for class_dir in train_dir.iterdir():
        if class_dir.is_dir():
            count = len([f for f in class_dir.iterdir() 
                        if f.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp']])
            total_train += count
            print(f"  è®­ç»ƒé›† {class_dir.name}: {count} å¼ ")
    
    for class_dir in val_dir.iterdir():
        if class_dir.is_dir():
            count = len([f for f in class_dir.iterdir() 
                        if f.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp']])
            total_val += count
            print(f"  éªŒè¯é›† {class_dir.name}: {count} å¼ ")
    
    print(f"ğŸ“ˆ æ€»è®¡: è®­ç»ƒé›† {total_train} å¼ , éªŒè¯é›† {total_val} å¼ ")
    
    if total_train < 50:
        print("âš ï¸  è­¦å‘Š: è®­ç»ƒé›†å›¾ç‰‡è¿‡å°‘ï¼Œå»ºè®®è‡³å°‘50å¼ ")
    
    if total_val < 20:
        print("âš ï¸  è­¦å‘Š: éªŒè¯é›†å›¾ç‰‡è¿‡å°‘ï¼Œå»ºè®®è‡³å°‘20å¼ ")
    
    return len(train_classes)

def get_optimal_training_config(num_classes, total_images):
    """æ ¹æ®æ•°æ®é›†å¤§å°è·å–æœ€ä¼˜è®­ç»ƒé…ç½®"""
    
    if total_images <= 100:
        # æå°æ•°æ®é›†
        config = {
            "model": "mobilenetv3_small_100",
            "batch_size": 8,
            "lr": 0.0005,
            "epochs": 200,
            "mixup": 0.6,
            "cutmix": 1.2,
            "reprob": 0.4,
            "aa": "rand-m20-mstd0.5-inc1"
        }
    elif total_images <= 200:
        # å°æ•°æ®é›† (æ¨èé…ç½®)
        config = {
            "model": "efficientnet_b0", 
            "batch_size": 16,
            "lr": 0.001,
            "epochs": 150,
            "mixup": 0.4,
            "cutmix": 1.0,
            "reprob": 0.3,
            "aa": "rand-m15-mstd0.5-inc1"
        }
    else:
        # ä¸­ç­‰æ•°æ®é›†
        config = {
            "model": "efficientnet_b0",
            "batch_size": 32,
            "lr": 0.01,
            "epochs": 100,
            "mixup": 0.2,
            "cutmix": 0.8,
            "reprob": 0.25,
            "aa": "rand-m9-mstd0.5-inc1"
        }
    
    return config

def run_training(dataset_path, num_classes, config, output_dir):
    """æ‰§è¡Œè®­ç»ƒ"""

    # ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒçš„Python
    python_exe = ".venv/Scripts/python.exe" if os.name == 'nt' else ".venv/bin/python"
    if not os.path.exists(python_exe):
        python_exe = "python"  # å›é€€åˆ°ç³»ç»ŸPython

    # æ„å»ºè®­ç»ƒå‘½ä»¤
    cmd = [
        python_exe, "train.py", str(dataset_path),
        "--model", config["model"],
        "--pretrained",
        "--num-classes", str(num_classes),
        "--batch-size", str(config["batch_size"]),
        "--lr", str(config["lr"]),
        "--epochs", str(config["epochs"]),
        "--opt", "adamw",
        "--weight-decay", "0.01",
        "--sched", "cosine",
        "--warmup-epochs", "10",
        "--aa", config["aa"],
        "--mixup", str(config["mixup"]),
        "--cutmix", str(config["cutmix"]),
        "--reprob", str(config["reprob"]),
        "--drop-path", "0.1",
        "--amp",
        "--model-ema",
        "--model-ema-decay", "0.9999",
        "--patience", "20",
        "--min-lr", "1e-6",
        "--output", str(output_dir),
        "--experiment", "small_dataset_training",
        "--log-interval", "5"
    ]
    
    print(f"ğŸš€ å¼€å§‹è®­ç»ƒ...")
    print(f"ğŸ“ è®­ç»ƒå‘½ä»¤: {' '.join(cmd)}")
    
    # æ‰§è¡Œè®­ç»ƒ
    try:
        result = subprocess.run(cmd, check=True, capture_output=False)
        print("âœ… è®­ç»ƒå®Œæˆ!")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        return False

def run_validation(dataset_path, model_name, checkpoint_path, output_dir):
    """æ‰§è¡ŒéªŒè¯"""

    # ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒçš„Python
    python_exe = ".venv/Scripts/python.exe" if os.name == 'nt' else ".venv/bin/python"
    if not os.path.exists(python_exe):
        python_exe = "python"  # å›é€€åˆ°ç³»ç»ŸPython

    cmd = [
        python_exe, "validate.py", str(dataset_path),
        "--model", model_name,
        "--checkpoint", str(checkpoint_path),
        "--batch-size", "32",
        "--amp",
        "--results-file", str(output_dir / "validation_results.csv")
    ]
    
    print(f"ğŸ” å¼€å§‹éªŒè¯...")
    print(f"ğŸ“ éªŒè¯å‘½ä»¤: {' '.join(cmd)}")
    
    try:
        result = subprocess.run(cmd, check=True, capture_output=False)
        print("âœ… éªŒè¯å®Œæˆ!")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ éªŒè¯å¤±è´¥: {e}")
        return False

def main():
    parser = argparse.ArgumentParser(description="200å¼ å›¾ç‰‡å°æ•°æ®é›†è®­ç»ƒè„šæœ¬")
    parser.add_argument("dataset_path", help="æ•°æ®é›†è·¯å¾„")
    parser.add_argument("--model", default="auto", help="æ¨¡å‹åç§° (é»˜è®¤: auto)")
    parser.add_argument("--output-dir", default=None, help="è¾“å‡ºç›®å½•")
    parser.add_argument("--skip-validation", action="store_true", help="è·³è¿‡éªŒè¯")
    
    args = parser.parse_args()
    
    print("ğŸ¯ 200å¼ å›¾ç‰‡å°æ•°æ®é›†è®­ç»ƒè„šæœ¬")
    print("=" * 50)
    
    try:
        # 1. æ£€æŸ¥æ•°æ®é›†
        print("\n1. ğŸ“Š æ£€æŸ¥æ•°æ®é›†ç»“æ„...")
        num_classes = check_dataset_structure(args.dataset_path)
        
        # 2. åˆ›å»ºè¾“å‡ºç›®å½•
        if args.output_dir:
            output_dir = Path(args.output_dir)
        else:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_dir = Path(f"./output_small_dataset_{timestamp}")
        
        output_dir.mkdir(parents=True, exist_ok=True)
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        
        # 3. è·å–æœ€ä¼˜é…ç½®
        print("\n2. âš™ï¸  è·å–æœ€ä¼˜è®­ç»ƒé…ç½®...")
        # ç®€å•ä¼°ç®—æ€»å›¾ç‰‡æ•°
        total_images = 200  # å‡è®¾å€¼ï¼Œå®é™…å¯ä»¥é€šè¿‡éå†è®¡ç®—
        config = get_optimal_training_config(num_classes, total_images)
        
        if args.model != "auto":
            config["model"] = args.model
        
        print(f"ğŸ¯ é€‰æ‹©æ¨¡å‹: {config['model']}")
        print(f"ğŸ“¦ æ‰¹æ¬¡å¤§å°: {config['batch_size']}")
        print(f"ğŸ“ˆ å­¦ä¹ ç‡: {config['lr']}")
        print(f"ğŸ”„ è®­ç»ƒè½®æ¬¡: {config['epochs']}")
        print(f"ğŸ¨ æ•°æ®å¢å¼º: {config['aa']}")
        
        # 4. æ‰§è¡Œè®­ç»ƒ
        print("\n3. ğŸš€ å¼€å§‹è®­ç»ƒ...")
        success = run_training(args.dataset_path, num_classes, config, output_dir)
        
        if not success:
            print("âŒ è®­ç»ƒå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
            return 1
        
        # 5. éªŒè¯æ¨¡å‹
        if not args.skip_validation:
            print("\n4. ğŸ” éªŒè¯æ¨¡å‹...")
            checkpoint_path = output_dir / "model_best.pth.tar"
            if checkpoint_path.exists():
                run_validation(args.dataset_path, config["model"], 
                             checkpoint_path, output_dir)
            else:
                print("âš ï¸  æ‰¾ä¸åˆ°æœ€ä½³æ¨¡å‹æ£€æŸ¥ç‚¹ï¼Œè·³è¿‡éªŒè¯")
        
        # 6. æ€»ç»“
        print("\n" + "=" * 50)
        print("ğŸ‰ è®­ç»ƒæµç¨‹å®Œæˆ!")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {output_dir}")
        print(f"ğŸ† æœ€ä½³æ¨¡å‹: {output_dir}/model_best.pth.tar")
        print(f"ğŸ“Š éªŒè¯ç»“æœ: {output_dir}/validation_results.csv")
        print(f"ğŸ“ˆ æŸ¥çœ‹è®­ç»ƒæ—¥å¿—: tensorboard --logdir {output_dir}")
        
        print("\nğŸ’¡ å°æ•°æ®é›†è®­ç»ƒæŠ€å·§æ€»ç»“:")
        print("1. âœ… ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹")
        print("2. âœ… å¼ºæ•°æ®å¢å¼º")
        print("3. âœ… å°å­¦ä¹ ç‡é•¿è®­ç»ƒ")
        print("4. âœ… æ—©åœé˜²è¿‡æ‹Ÿåˆ")
        print("5. âœ… æ¨¡å‹EMAæå‡ç¨³å®šæ€§")
        
        return 0
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        return 1

if __name__ == "__main__":
    exit(main())
