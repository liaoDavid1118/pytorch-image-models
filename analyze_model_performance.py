#!/usr/bin/env python3
"""
æ¨¡å‹æ€§èƒ½åˆ†æè„šæœ¬
åˆ†æè®­ç»ƒå¥½çš„bilei vs waiguanåˆ†ç±»æ¨¡å‹çš„è¯¦ç»†æ€§èƒ½
"""

import torch
import timm
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc
from sklearn.preprocessing import label_binarize
import json
from pathlib import Path
from PIL import Image
import pandas as pd

class ModelAnalyzer:
    def __init__(self, model_path, dataset_path, device='cpu'):
        """
        åˆå§‹åŒ–æ¨¡å‹åˆ†æå™¨
        
        Args:
            model_path: æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„
            dataset_path: æ•°æ®é›†è·¯å¾„
            device: è®¡ç®—è®¾å¤‡
        """
        self.device = device
        self.dataset_path = Path(dataset_path)
        self.class_names = ['bilei', 'waiguan']
        
        # åŠ è½½æ¨¡å‹
        self.model = timm.create_model('efficientnet_b0', num_classes=2)
        checkpoint = torch.load(model_path, map_location=device)
        if 'state_dict' in checkpoint:
            state_dict = checkpoint['state_dict']
        else:
            state_dict = checkpoint
        self.model.load_state_dict(state_dict)
        self.model.eval()
        self.model.to(device)
        
        # æ•°æ®é¢„å¤„ç†
        self.data_config = timm.data.resolve_data_config({}, model=self.model)
        self.transform = timm.data.create_transform(**self.data_config, is_training=False)
        
        print(f"âœ… æ¨¡å‹åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")

    def load_dataset_split(self, split='test'):
        """åŠ è½½æŒ‡å®šæ•°æ®é›†åˆ†å‰²"""
        split_path = self.dataset_path / split
        
        images = []
        labels = []
        image_paths = []
        
        for class_idx, class_name in enumerate(self.class_names):
            class_path = split_path / class_name
            if not class_path.exists():
                continue
                
            for img_path in class_path.glob('*'):
                if img_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp']:
                    images.append(img_path)
                    labels.append(class_idx)
                    image_paths.append(str(img_path))
        
        return images, labels, image_paths

    def predict_dataset(self, images, labels):
        """å¯¹æ•°æ®é›†è¿›è¡Œé¢„æµ‹"""
        predictions = []
        probabilities = []
        
        print(f"ğŸ” æ­£åœ¨é¢„æµ‹ {len(images)} å¼ å›¾ç‰‡...")
        
        for i, img_path in enumerate(images):
            try:
                # åŠ è½½å’Œé¢„å¤„ç†å›¾ç‰‡
                image = Image.open(img_path).convert('RGB')
                input_tensor = self.transform(image).unsqueeze(0).to(self.device)
                
                # é¢„æµ‹
                with torch.no_grad():
                    outputs = self.model(input_tensor)
                    probs = torch.nn.functional.softmax(outputs, dim=1)
                    pred = torch.argmax(probs, dim=1)
                    
                predictions.append(pred.item())
                probabilities.append(probs.cpu().numpy()[0])
                
                if (i + 1) % 50 == 0:
                    print(f"   å·²å¤„ç†: {i + 1}/{len(images)}")
                    
            except Exception as e:
                print(f"âŒ å¤„ç†å¤±è´¥ {img_path}: {e}")
                predictions.append(-1)  # é”™è¯¯æ ‡è®°
                probabilities.append([0, 0])
        
        return np.array(predictions), np.array(probabilities)

    def generate_confusion_matrix(self, y_true, y_pred, save_path=None):
        """ç”Ÿæˆæ··æ·†çŸ©é˜µ"""
        cm = confusion_matrix(y_true, y_pred)
        
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                   xticklabels=self.class_names,
                   yticklabels=self.class_names)
        plt.title('æ··æ·†çŸ©é˜µ (Confusion Matrix)')
        plt.ylabel('çœŸå®æ ‡ç­¾ (True Label)')
        plt.xlabel('é¢„æµ‹æ ‡ç­¾ (Predicted Label)')
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š æ··æ·†çŸ©é˜µå·²ä¿å­˜: {save_path}")
        
        plt.show()
        return cm

    def generate_classification_report(self, y_true, y_pred):
        """ç”Ÿæˆåˆ†ç±»æŠ¥å‘Š"""
        report = classification_report(y_true, y_pred, 
                                     target_names=self.class_names,
                                     output_dict=True)
        
        print("ğŸ“‹ è¯¦ç»†åˆ†ç±»æŠ¥å‘Š:")
        print("=" * 50)
        print(classification_report(y_true, y_pred, target_names=self.class_names))
        
        return report

    def plot_roc_curve(self, y_true, y_probs, save_path=None):
        """ç»˜åˆ¶ROCæ›²çº¿"""
        plt.figure(figsize=(10, 8))
        
        # äºŒåˆ†ç±»ROCæ›²çº¿
        fpr, tpr, _ = roc_curve(y_true, y_probs[:, 1])
        roc_auc = auc(fpr, tpr)
        
        plt.plot(fpr, tpr, color='darkorange', lw=2,
                label=f'ROCæ›²çº¿ (AUC = {roc_auc:.3f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('å‡æ­£ç‡ (False Positive Rate)')
        plt.ylabel('çœŸæ­£ç‡ (True Positive Rate)')
        plt.title('ROCæ›²çº¿')
        plt.legend(loc="lower right")
        plt.grid(True)
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“ˆ ROCæ›²çº¿å·²ä¿å­˜: {save_path}")
        
        plt.show()
        return roc_auc

    def analyze_confidence_distribution(self, y_true, y_probs, save_path=None):
        """åˆ†æç½®ä¿¡åº¦åˆ†å¸ƒ"""
        confidences = np.max(y_probs, axis=1)
        correct_mask = (np.argmax(y_probs, axis=1) == y_true)
        
        plt.figure(figsize=(12, 5))
        
        # æ­£ç¡®é¢„æµ‹çš„ç½®ä¿¡åº¦åˆ†å¸ƒ
        plt.subplot(1, 2, 1)
        plt.hist(confidences[correct_mask], bins=20, alpha=0.7, color='green', label='æ­£ç¡®é¢„æµ‹')
        plt.hist(confidences[~correct_mask], bins=20, alpha=0.7, color='red', label='é”™è¯¯é¢„æµ‹')
        plt.xlabel('ç½®ä¿¡åº¦')
        plt.ylabel('é¢‘æ¬¡')
        plt.title('é¢„æµ‹ç½®ä¿¡åº¦åˆ†å¸ƒ')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # å„ç±»åˆ«çš„ç½®ä¿¡åº¦åˆ†å¸ƒ
        plt.subplot(1, 2, 2)
        for i, class_name in enumerate(self.class_names):
            class_mask = (y_true == i)
            class_confidences = confidences[class_mask]
            plt.hist(class_confidences, bins=15, alpha=0.7, label=f'{class_name}')
        
        plt.xlabel('ç½®ä¿¡åº¦')
        plt.ylabel('é¢‘æ¬¡')
        plt.title('å„ç±»åˆ«ç½®ä¿¡åº¦åˆ†å¸ƒ')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š ç½®ä¿¡åº¦åˆ†å¸ƒå›¾å·²ä¿å­˜: {save_path}")
        
        plt.show()

    def find_misclassified_samples(self, images, y_true, y_pred, y_probs, top_k=5):
        """æ‰¾å‡ºåˆ†ç±»é”™è¯¯çš„æ ·æœ¬"""
        misclassified_indices = np.where(y_true != y_pred)[0]
        
        if len(misclassified_indices) == 0:
            print("ğŸ‰ æ²¡æœ‰åˆ†ç±»é”™è¯¯çš„æ ·æœ¬ï¼")
            return []
        
        # æŒ‰ç½®ä¿¡åº¦æ’åºï¼Œæ‰¾å‡ºæœ€"è‡ªä¿¡"çš„é”™è¯¯é¢„æµ‹
        confidences = np.max(y_probs[misclassified_indices], axis=1)
        sorted_indices = misclassified_indices[np.argsort(confidences)[::-1]]
        
        print(f"âŒ å‘ç° {len(misclassified_indices)} ä¸ªåˆ†ç±»é”™è¯¯çš„æ ·æœ¬")
        print(f"ğŸ“‹ ç½®ä¿¡åº¦æœ€é«˜çš„ {min(top_k, len(sorted_indices))} ä¸ªé”™è¯¯æ ·æœ¬:")
        
        misclassified_samples = []
        for i, idx in enumerate(sorted_indices[:top_k]):
            true_label = self.class_names[y_true[idx]]
            pred_label = self.class_names[y_pred[idx]]
            confidence = np.max(y_probs[idx])
            
            sample_info = {
                'image_path': str(images[idx]),
                'true_label': true_label,
                'predicted_label': pred_label,
                'confidence': confidence,
                'probabilities': {
                    self.class_names[j]: y_probs[idx][j] for j in range(len(self.class_names))
                }
            }
            
            misclassified_samples.append(sample_info)
            
            print(f"  {i+1}. {Path(images[idx]).name}")
            print(f"     çœŸå®: {true_label} | é¢„æµ‹: {pred_label} | ç½®ä¿¡åº¦: {confidence:.3f}")
        
        return misclassified_samples

    def comprehensive_analysis(self, split='test', output_dir='./analysis_results'):
        """æ‰§è¡Œå…¨é¢çš„æ¨¡å‹åˆ†æ"""
        output_dir = Path(output_dir)
        output_dir.mkdir(exist_ok=True)
        
        print(f"ğŸ”¬ å¼€å§‹å…¨é¢åˆ†ææ¨¡å‹æ€§èƒ½ (æ•°æ®é›†: {split})")
        print("=" * 60)
        
        # 1. åŠ è½½æ•°æ®
        images, labels, image_paths = self.load_dataset_split(split)
        print(f"ğŸ“Š æ•°æ®é›†ç»Ÿè®¡:")
        print(f"   æ€»æ ·æœ¬æ•°: {len(images)}")
        for i, class_name in enumerate(self.class_names):
            count = sum(1 for label in labels if label == i)
            print(f"   {class_name}: {count} å¼ ")
        
        # 2. æ¨¡å‹é¢„æµ‹
        predictions, probabilities = self.predict_dataset(images, labels)
        
        # 3. åŸºæœ¬æ€§èƒ½æŒ‡æ ‡
        accuracy = np.mean(predictions == labels)
        print(f"\nğŸ¯ æ•´ä½“å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy*100:.2f}%)")
        
        # 4. ç”Ÿæˆæ··æ·†çŸ©é˜µ
        cm = self.generate_confusion_matrix(labels, predictions, 
                                          output_dir / 'confusion_matrix.png')
        
        # 5. åˆ†ç±»æŠ¥å‘Š
        report = self.generate_classification_report(labels, predictions)
        
        # 6. ROCæ›²çº¿
        roc_auc = self.plot_roc_curve(labels, probabilities,
                                    output_dir / 'roc_curve.png')
        
        # 7. ç½®ä¿¡åº¦åˆ†æ
        self.analyze_confidence_distribution(labels, probabilities,
                                           output_dir / 'confidence_distribution.png')
        
        # 8. é”™è¯¯æ ·æœ¬åˆ†æ
        misclassified = self.find_misclassified_samples(images, labels, predictions, probabilities)
        
        # 9. ä¿å­˜è¯¦ç»†ç»“æœ
        results = {
            'dataset_split': split,
            'total_samples': len(images),
            'accuracy': float(accuracy),
            'roc_auc': float(roc_auc),
            'classification_report': report,
            'confusion_matrix': cm.tolist(),
            'misclassified_samples': misclassified
        }
        
        with open(output_dir / 'analysis_results.json', 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
        print(f"ğŸ“ åŒ…å«æ–‡ä»¶:")
        print(f"   - analysis_results.json (è¯¦ç»†ç»“æœ)")
        print(f"   - confusion_matrix.png (æ··æ·†çŸ©é˜µ)")
        print(f"   - roc_curve.png (ROCæ›²çº¿)")
        print(f"   - confidence_distribution.png (ç½®ä¿¡åº¦åˆ†å¸ƒ)")
        
        return results

def main():
    # é…ç½®å‚æ•°
    model_path = "./output_bilei_waiguan/bilei_waiguan_classification/model_best.pth.tar"
    dataset_path = "./dataset"
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = ModelAnalyzer(model_path, dataset_path, device='cpu')
    
    # æ‰§è¡Œå…¨é¢åˆ†æ
    results = analyzer.comprehensive_analysis(split='test')
    
    print("\nğŸ‰ æ¨¡å‹åˆ†æå®Œæˆï¼")

if __name__ == "__main__":
    main()
